{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reading the data in a custom data structure: \n",
    "\n",
    "- We have several files, each one of this for each company. The files have the info of stock daily prices from 2007-1-1 to 2017-04-17.\n",
    "\n",
    "- The columns names are: date, close (close price), open (open price), high, low, volume\n",
    "\n",
    "We need three layers of Ã­ndices to get acces to specific values of all the data. A good data structure can be: \n",
    "\n",
    "hash table --> List --> List \n",
    "\n",
    "Each hash (associated to each hash - table) for each stock symbol (company)\n",
    "List of Lists: List of rows of daily prices for each key in the hash table (we can use a dictionary). \n",
    "\n",
    "Since we need to get quick access to a stock symbol, its convenient to  have a hash table for each although the tradeoff for this is slightly higher memory usage.\n",
    "\n",
    "In the next layers using again a hash table we increments considerably the memory usage, instead of that, we can use a List of List for the second and third layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dgica.csv',\n",
       " 'bdge.csv',\n",
       " 'cvco.csv',\n",
       " 'blkb.csv',\n",
       " 'bbox.csv',\n",
       " 'ffbc.csv',\n",
       " 'fbiz.csv',\n",
       " 'ffic.csv',\n",
       " 'bdsi.csv',\n",
       " 'amgn.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(\"prices\")\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2590, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>19.99</td>\n",
       "      <td>19.650000</td>\n",
       "      <td>20.120001</td>\n",
       "      <td>19.590000</td>\n",
       "      <td>30100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>16800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>19.02</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>27700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>18.58</td>\n",
       "      <td>19.059999</td>\n",
       "      <td>19.059999</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>30300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>18.57</td>\n",
       "      <td>18.540001</td>\n",
       "      <td>18.639999</td>\n",
       "      <td>18.410000</td>\n",
       "      <td>37800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  close       open       high        low  volume\n",
       "0  2007-01-03  19.99  19.650000  20.120001  19.590000   30100\n",
       "1  2007-01-04  20.00  20.000000  20.000000  19.700001   16800\n",
       "2  2007-01-05  19.02  19.870001  19.870001  19.020000   27700\n",
       "3  2007-01-08  18.58  19.059999  19.059999  18.500000   30300\n",
       "4  2007-01-09  18.57  18.540001  18.639999  18.410000   37800"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prueba: Reading only one file into pandas.DataFrame to \n",
    "# see how the data is structured in each file.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"prices/dgica.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_files(file_name):\n",
    "    with open(\"prices/\"+file_name,\"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        all_lines = [p.strip().split(\",\") for p in lines][1:]\n",
    "        all_lines = [d for d in all_lines]\n",
    "        return (file_name.replace(\".csv\",\"\"),all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers = 3)\n",
    "data = list(pool.map(read_files,files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stored the data in the \"data\" dictionary according to the previous diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2007-01-03', '68.400002', '68.43', '69.480003', '67.849998', '12908400'],\n",
       " ['2007-01-04',\n",
       "  '71.330002',\n",
       "  '69.480003',\n",
       "  '71.870003',\n",
       "  '68.970001',\n",
       "  '16000900'],\n",
       " ['2007-01-05', '71.50', '71.339996', '72.080002', '71.010002', '10462000'],\n",
       " ['2007-01-08', '70.93', '71.629997', '71.889999', '70.790001', '6747100'],\n",
       " ['2007-01-09', '71.269997', '71.169998', '71.68', '70.669998', '7165200'],\n",
       " ['2007-01-10', '71.040001', '70.900002', '71.239998', '70.699997', '5780600'],\n",
       " ['2007-01-11', '71.910004', '71.160004', '72.209999', '70.739998', '6872600'],\n",
       " ['2007-01-12', '73.269997', '72.019997', '73.57', '72.00', '10115000'],\n",
       " ['2007-01-16', '73.50', '73.400002', '73.580002', '72.769997', '5465400'],\n",
       " ['2007-01-17', '73.93', '73.50', '74.080002', '73.199997', '6535100']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"amgn\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating some aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.23"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average closing price for each stocks\n",
    "\n",
    "average_closing_prices = {}\n",
    "\n",
    "for k,v in data.items():\n",
    "    suma = 0\n",
    "    for row in v:\n",
    "        suma += float(row[1])\n",
    "    average_closing_prices[k] = round(suma/len(v),2)\n",
    "    \n",
    "average_closing_prices[\"amgn\"] # result for \"amgn\" company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6412205.17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average volume for each stock\n",
    "\n",
    "average_volume = {}\n",
    "\n",
    "for k,v in data.items():\n",
    "    suma = 0\n",
    "    for row in v:\n",
    "        suma += float(row[5])\n",
    "    average_volume[k] = round(suma/len(v),2)\n",
    "    \n",
    "average_volume[\"amgn\"] # result for \"amgn\" company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average opening price for each stocks\n",
    "\n",
    "average_opening_prices = {}\n",
    "\n",
    "for k,v in data.items():\n",
    "    suma = 0\n",
    "    for row in v:\n",
    "        suma += float(row[2])\n",
    "    average_opening_prices[k] = round(suma/len(v),2)\n",
    "    \n",
    "average_opening_prices[\"amgn\"] # result for \"amgn\" company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference between the average opening price and the\n",
    "# average closing price for each stock.\n",
    "\n",
    "average_delta_prices = {}\n",
    "\n",
    "for k in average_opening_prices.keys():\n",
    "    average_delta_prices[k] = round(average_closing_prices[k]\\\n",
    "                              - average_opening_prices[k],2)\n",
    "        \n",
    "average_delta_prices[\"amgn\"] # result for \"amgn\" company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.94"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference between the average high and \n",
    "# the average low for each stock.\n",
    "\n",
    "average_high = {}\n",
    "\n",
    "for k,v in data.items():\n",
    "    suma = 0\n",
    "    for row in v:\n",
    "        suma += float(row[3])\n",
    "    average_high[k] = round(suma/len(v),2)\n",
    "    \n",
    "average_low = {}\n",
    "\n",
    "for k,v in data.items():\n",
    "    suma = 0\n",
    "    for row in v:\n",
    "        suma += float(row[4])\n",
    "    average_low[k] = round(suma/len(v),2)\n",
    "    \n",
    "high_low_average_diff = {}\n",
    "\n",
    "for k in average_low.keys():\n",
    "    high_low_average_diff[k] = round(average_high[k]\\\n",
    "                              - average_low[k],2)\n",
    "        \n",
    "high_low_average_diff[\"amgn\"] # result for \"amgn\" company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to compute aggregates: transforming data structure: \n",
    "\n",
    "\n",
    "    Layer 1 -- hash table (each stock symbol is a key)\n",
    "    Layer 2 -- hash table (each column header is a key)\n",
    "    Layer 3 -- array.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2007, 1, 3, 0, 0),\n",
       " datetime.datetime(2007, 1, 4, 0, 0),\n",
       " datetime.datetime(2007, 1, 5, 0, 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = {}\n",
    "\n",
    "columns = [\"date\",\"close\",\"open\",\"high\",\"low\",\"volume\"]\n",
    "\n",
    "for k,v in data.items():\n",
    "    dic = {}\n",
    "    for i,column in enumerate(columns):\n",
    "        if column == \"date\":\n",
    "            dic[column] = [datetime.strptime(v[j][i],\"%Y-%m-%d\") \\\n",
    "                           for j in range(len(v))]\n",
    "        elif column == \"volume\":\n",
    "            dic[column] = [int(v[j][i]) \\\n",
    "                           for j in range(len(v))]\n",
    "        else: \n",
    "            dic[column] = [round(float(v[j][i]),2) \\\n",
    "                           for j in range(len(v))]\n",
    "    new_data[k] = dic\n",
    "\n",
    "\n",
    "new_data[\"aapl\"][\"date\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we have data structured as the following form: \n",
    "\n",
    "{\n",
    "    'aapl': {\n",
    "        \"date\": [\n",
    "                \"2007-01-03\",\n",
    "                \"2007-01-04\",\n",
    "                ...\n",
    "            ],\n",
    "        \"close\": [\n",
    "                83.800002,\n",
    "                85.659998,\n",
    "                ...\n",
    "            ],\n",
    "        ...\n",
    "\n",
    "    },\n",
    "    'goog': {\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "\n",
    "###### in this kind of data structure we can access values like in pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[309579900, 211815100, 208685400]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"aapl\"][\"volume\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86.58, 85.95, 86.2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"aapl\"][\"high\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.23 average_closing for amgn\n",
      "6412205.17 average volume for amgn\n",
      "92.22 average opening for amgn\n",
      "0.01 average delta close-open for amgn\n",
      "93.18 average high for amgn\n",
      "91.24 average low for amgn\n",
      "1.94 average high low difference for amgn\n"
     ]
    }
   ],
   "source": [
    "# Then calculating the same aggregates as before: \n",
    "\n",
    "# Average closing price for each stocks\n",
    "\n",
    "average_closing_prices_v2 = {}\n",
    "\n",
    "for k,v in new_data.items():\n",
    "    average_closing_prices_v2[k] = \\\n",
    "    round(sum(new_data[k][\"close\"])/\\\n",
    "          len(new_data[k][\"close\"]),2)\n",
    "    \n",
    "print(average_closing_prices_v2[\"amgn\"], \"average_closing for amgn\") \n",
    "# result for \"amgn\" company\n",
    "\n",
    "average_volume_v2 = {}\n",
    "\n",
    "for k,v in new_data.items():\n",
    "    average_volume_v2[k] = \\\n",
    "    round(sum(new_data[k][\"volume\"])/\\\n",
    "          len(new_data[k][\"volume\"]),2)\n",
    "    \n",
    "print(average_volume_v2[\"amgn\"], \"average volume for amgn\") \n",
    "# result for \"amgn\" company\n",
    "\n",
    "average_opening_prices_v2 = {}\n",
    "\n",
    "for k,v in new_data.items():\n",
    "    average_opening_prices_v2[k] = \\\n",
    "    round(sum(new_data[k][\"open\"])/\\\n",
    "          len(new_data[k][\"open\"]),2)\n",
    "    \n",
    "print(average_opening_prices_v2[\"amgn\"],\"average opening for amgn\") \n",
    "# result for \"amgn\" company\n",
    "\n",
    "\n",
    "average_delta_prices_v2 = {}\n",
    "\n",
    "for k in average_opening_prices_v2.keys():\n",
    "    average_delta_prices_v2[k] = \\\n",
    "          round(average_closing_prices_v2[k]\\\n",
    "            - average_opening_prices_v2[k],2)\n",
    "        \n",
    "print(average_delta_prices_v2[\"amgn\"],\"average delta close-open for amgn\")\n",
    "# result for \"amgn\" company\n",
    "\n",
    "average_high_v2 = {}\n",
    "\n",
    "for k,v in new_data.items():\n",
    "    average_high_v2[k] = \\\n",
    "    round(sum(new_data[k][\"high\"])/\\\n",
    "          len(new_data[k][\"high\"]),2)\n",
    "    \n",
    "print(average_high_v2[\"amgn\"],\"average high for amgn\") \n",
    "# result for \"amgn\" company\n",
    "    \n",
    "average_low_v2 = {}\n",
    "\n",
    "for k,v in new_data.items():\n",
    "    average_low_v2[k] = \\\n",
    "    round(sum(new_data[k][\"low\"])/\\\n",
    "          len(new_data[k][\"low\"]),2)\n",
    "    \n",
    "print(average_low_v2[\"amgn\"],\"average low for amgn\") \n",
    "# result for \"amgn\" company\n",
    "    \n",
    "high_low_average_diff_v2 = {}\n",
    "\n",
    "for k in average_low.keys():\n",
    "    high_low_average_diff_v2[k] = round(average_high_v2[k]\\\n",
    "                              - average_low_v2[k],2)\n",
    "        \n",
    "print(high_low_average_diff_v2[\"amgn\"],\"average high low difference for amgn\")\n",
    "# result for \"amgn\" company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching on data (binary search):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional aggregates\n",
    "\n",
    "total_volume_each_day = {}\n",
    "\n",
    "for company in new_data:\n",
    "    for i,day in enumerate(new_data[company][\"date\"]):\n",
    "        if day not in total_volume_each_day:\n",
    "            total_volume_each_day[day] = \\\n",
    "            new_data[company][\"volume\"][0]\n",
    "        else:\n",
    "            total_volume_each_day[day] += \\\n",
    "            new_data[company][\"volume\"][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_volume_each_day.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining some already known functions to sort values \n",
    "# Using insertion sort.\n",
    "\n",
    "def swap(array, pos1, pos2): \n",
    "    first_value_stored = array[pos1]\n",
    "    array[pos1] = array[pos2]\n",
    "    array[pos2] = first_value_stored\n",
    "    return array\n",
    "\n",
    "def insertion_sort_vinculated_arrays(array_index,array):\n",
    "    for i in range(1,len(array_index)):\n",
    "        j = i\n",
    "        while j>0 and (array_index[j-1]>array_index[j]):\n",
    "            swap(array_index,j-1,j)\n",
    "            swap(array,j-1,j)\n",
    "            j -= 1\n",
    "            \n",
    "def binary_search(array, search):\n",
    "    \n",
    "    insertion_sort(array)\n",
    "    m = 0\n",
    "    i = 0\n",
    "    z = len(array) - 1\n",
    "    while i<= z:\n",
    "        \n",
    "        m = math.floor(i + ((z - i) / 2))\n",
    "        if array[m] == search:\n",
    "            return m\n",
    "        elif array[m] < search:\n",
    "            i = m + 1\n",
    "        elif array[m] > search:\n",
    "            z = m - 1\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "days_list = sorted([day for day in total_volume_each_day])\n",
    "volumes_list = [total_volume_each_day[day] for day in days_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1578732000, 1599461700, 1611417400, 1769830800, 1963904000]\n",
      " \n",
      "[datetime.datetime(2008, 1, 22, 0, 0), datetime.datetime(2008, 10, 8, 0, 0), datetime.datetime(2007, 7, 26, 0, 0), datetime.datetime(2008, 10, 10, 0, 0), datetime.datetime(2008, 1, 23, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "# Sorting the days - volume vinculated lists:\n",
    "\n",
    "insertion_sort_vinculated_arrays(volumes_list,days_list)\n",
    "print(volumes_list[-5:])\n",
    "print(\" \")\n",
    "print(days_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2008, 1, 23, 0, 0),\n",
       " datetime.datetime(2008, 10, 10, 0, 0),\n",
       " datetime.datetime(2007, 7, 26, 0, 0),\n",
       " datetime.datetime(2008, 10, 8, 0, 0),\n",
       " datetime.datetime(2008, 1, 22, 0, 0),\n",
       " datetime.datetime(2008, 2, 7, 0, 0),\n",
       " datetime.datetime(2008, 9, 29, 0, 0),\n",
       " datetime.datetime(2007, 11, 8, 0, 0),\n",
       " datetime.datetime(2008, 1, 16, 0, 0),\n",
       " datetime.datetime(2008, 1, 24, 0, 0)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_volume_days = [days_list[-i] for i in range(1,11)]\n",
    "top10_volume_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, finding all prices for all stocks on each of the 10 high volume days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prices_top_10_days = {}\n",
    "\n",
    "for day in top10_volume_days:\n",
    "    prices = []\n",
    "    for company in new_data:\n",
    "        result = binary_search(new_data[company][\"date\"],day)\n",
    "        if result is not None: \n",
    "            price = new_data[company][\"close\"][result]\n",
    "            prices.append((company,price))\n",
    "    prices_top_10_days[day] = prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most profitable stocks from 2007 to present and the fastest growing companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Easy task: \n",
    "\n",
    "companies = []\n",
    "percentages = []\n",
    "\n",
    "companies_growth_dict = {}\n",
    "\n",
    "for company in new_data:\n",
    "    companies.append(company)\n",
    "    initial_price = new_data[company][\"open\"][0]\n",
    "    final_day_index = len(new_data[company][\"date\"]) - 1\n",
    "    final_price = new_data[company][\"open\"][final_day_index]\n",
    "    percentage = round(final_price / initial_price - 1,2)\n",
    "    percentages.append(percentage)\n",
    "    # storing company - percentages \n",
    "    companies_growth_dict[company] = percentage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admp', 'adxs', 'arcw', 'blfs', 'amzn', 'anip', 'apdn', 'cui', 'axgn', 'achc']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertion_sort_vinculated_arrays(percentages,companies)\n",
    "\n",
    "top10_growth_companies = [companies[-i] for i in range(1,11)]\n",
    "\n",
    "top10_growth_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps in further data science analysis:\n",
    "\n",
    "\n",
    "-    What stocks would have been best to short at the start of the period?\n",
    "-    Which stocks have the most after-hours trading, and show the biggest changes between the closing price and the next day open?\n",
    "-    Can technical indicators like Bollinger Bands help us forecast the market?\n",
    "-    What time periods have resulted in steady increases in prices, and what periods have resulted in steady declines?\n",
    "-    Based on price, what was the optimal day to buy each stock if we wanted to hold them until now?\n",
    "-    On days with high trading volume, do stocks move in one direction (up or down) more than the other one?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
